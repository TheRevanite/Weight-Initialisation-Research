{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2461f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/50], Train Acc: 20.44%, Val Acc: 26.90%, Train Loss: 2.4926, Val Loss: 1.9923\n",
      "Epoch [2/50], Train Acc: 25.52%, Val Acc: 29.85%, Train Loss: 2.0124, Val Loss: 1.8017\n",
      "Epoch [3/50], Train Acc: 28.50%, Val Acc: 32.90%, Train Loss: 1.9002, Val Loss: 1.7105\n",
      "Epoch [4/50], Train Acc: 31.34%, Val Acc: 31.01%, Train Loss: 1.8287, Val Loss: 1.7921\n",
      "Epoch [5/50], Train Acc: 34.42%, Val Acc: 35.91%, Train Loss: 1.7443, Val Loss: 1.7347\n",
      "Epoch [6/50], Train Acc: 36.54%, Val Acc: 41.77%, Train Loss: 1.6866, Val Loss: 1.5277\n",
      "Epoch [7/50], Train Acc: 39.86%, Val Acc: 42.25%, Train Loss: 1.6191, Val Loss: 1.5363\n",
      "Epoch [8/50], Train Acc: 43.02%, Val Acc: 43.66%, Train Loss: 1.5576, Val Loss: 1.5063\n",
      "Epoch [9/50], Train Acc: 43.18%, Val Acc: 43.39%, Train Loss: 1.5375, Val Loss: 1.5301\n",
      "Epoch [10/50], Train Acc: 44.70%, Val Acc: 41.17%, Train Loss: 1.5042, Val Loss: 1.6210\n",
      "Epoch [11/50], Train Acc: 45.94%, Val Acc: 45.14%, Train Loss: 1.4576, Val Loss: 1.5173\n",
      "Epoch [12/50], Train Acc: 46.82%, Val Acc: 50.49%, Train Loss: 1.4452, Val Loss: 1.3579\n",
      "Epoch [13/50], Train Acc: 49.60%, Val Acc: 50.35%, Train Loss: 1.4188, Val Loss: 1.3598\n",
      "Epoch [14/50], Train Acc: 49.08%, Val Acc: 50.34%, Train Loss: 1.3818, Val Loss: 1.4063\n",
      "Epoch [15/50], Train Acc: 49.60%, Val Acc: 50.35%, Train Loss: 1.3804, Val Loss: 1.3648\n",
      "Epoch [16/50], Train Acc: 51.58%, Val Acc: 52.42%, Train Loss: 1.3337, Val Loss: 1.3369\n",
      "Epoch [17/50], Train Acc: 52.38%, Val Acc: 52.50%, Train Loss: 1.2969, Val Loss: 1.3287\n",
      "Epoch [18/50], Train Acc: 54.18%, Val Acc: 54.77%, Train Loss: 1.2896, Val Loss: 1.2525\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "# STL10 transforms with Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(64, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Resize((64, 64)),  # Resize from 96x96 to 64x64\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# STL10 dataset\n",
    "train_dataset = torchvision.datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Custom Initialization: He for shallow, Orthogonal for deep\n",
    "def custom_init(model):\n",
    "    relu_gain = nn.init.calculate_gain('relu')\n",
    "    layer_idx = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            if layer_idx < 10:\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.orthogonal_(m.weight, gain=relu_gain)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            layer_idx += 1\n",
    "\n",
    "# Modify ResNet18 with Dropout in the Fully Connected Layer\n",
    "class ResNet18Modified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Modified, self).__init__()\n",
    "        self.model = resnet18()\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.model.fc.in_features, 10)\n",
    "        )\n",
    "        custom_init(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ResNet18Modified().to(device)\n",
    "\n",
    "# Loss and optimizer with weight decay for L2 regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Train the model\n",
    "train_acc_list, val_acc_list = [], []\n",
    "train_loss_list, val_loss_list = [], []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total, correct, train_loss = 0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total, val_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_loss_list.append(val_loss / len(test_loader))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, \"\n",
    "          f\"Train Loss: {train_loss_list[-1]:.4f}, Val Loss: {val_loss_list[-1]:.4f}\")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {duration:.2f} seconds.\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "plt.plot(val_loss_list, label='Val Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_list, label='Train Acc')\n",
    "plt.plot(val_acc_list, label='Val Acc')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
