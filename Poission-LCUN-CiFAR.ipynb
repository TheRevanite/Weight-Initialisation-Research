{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f892e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 54.39it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 1.7099, Acc: 0.3808, Precision: 0.3744, Recall: 0.3808, F1: 0.3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.71it/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss: 1.4441, Acc: 0.4866, Precision: 0.4818, Recall: 0.4866, F1: 0.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.20it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss: 1.3139, Acc: 0.5331, Precision: 0.5286, Recall: 0.5331, F1: 0.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.16it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss: 1.2179, Acc: 0.5654, Precision: 0.5614, Recall: 0.5654, F1: 0.5627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.55it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss: 1.1318, Acc: 0.5971, Precision: 0.5937, Recall: 0.5971, F1: 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.60it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss: 1.0576, Acc: 0.6226, Precision: 0.6201, Recall: 0.6226, F1: 0.6209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.39it/s, loss=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss: 0.9941, Acc: 0.6463, Precision: 0.6437, Recall: 0.6463, F1: 0.6446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.24it/s, loss=0.925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss: 0.9246, Acc: 0.6696, Precision: 0.6678, Recall: 0.6696, F1: 0.6684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.14it/s, loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss: 0.8667, Acc: 0.6905, Precision: 0.6888, Recall: 0.6905, F1: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 54.18it/s, loss=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss: 0.8114, Acc: 0.7094, Precision: 0.7078, Recall: 0.7094, F1: 0.7084\n",
      "Test Accuracy: 0.5366, Precision: 0.5392, Recall: 0.5366, F1: 0.5356\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define Mish activation\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(torch.nn.functional.softplus(x))\n",
    "\n",
    "# LSUV (Layer-sequential unit variance) Initialization\n",
    "@torch.no_grad()\n",
    "def lsuv_init(model, data_loader, device):\n",
    "    \"\"\"Applies LSUV initialization to a model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.normal_(0, 1)\n",
    "            module.bias.zero_()\n",
    "    \n",
    "    for images, _ in data_loader:\n",
    "        images = images.to(device)\n",
    "        break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(images)\n",
    "        std = output.std().item()\n",
    "        if std > 1e-6:\n",
    "            for module in model.modules():\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    module.weight.data /= std\n",
    "    return model\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.mish1 = Mish()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.mish2 = Mish()\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.mish1(self.bn1(self.fc1(x)))\n",
    "        x = self.mish2(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNet().to(device)\n",
    "model = lsuv_init(model, trainloader, device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix(loss=running_loss / len(trainloader))\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Epoch {epoch+1}: Loss: {running_loss / len(trainloader):.4f}, Acc: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "test_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0c7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605e68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.25it/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 1.6052, Acc: 0.4314, Precision: 0.4255, Recall: 0.4314, F1: 0.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 57.24it/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss: 1.3900, Acc: 0.5094, Precision: 0.5040, Recall: 0.5094, F1: 0.5054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.00it/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss: 1.2834, Acc: 0.5464, Precision: 0.5423, Recall: 0.5464, F1: 0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 55.06it/s, loss=1.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss: 1.1975, Acc: 0.5781, Precision: 0.5739, Recall: 0.5781, F1: 0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 54.43it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss: 1.1243, Acc: 0.6054, Precision: 0.6022, Recall: 0.6054, F1: 0.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.05it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss: 1.0538, Acc: 0.6270, Precision: 0.6243, Recall: 0.6270, F1: 0.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 54.90it/s, loss=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss: 0.9912, Acc: 0.6479, Precision: 0.6452, Recall: 0.6479, F1: 0.6462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.44it/s, loss=0.931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss: 0.9305, Acc: 0.6707, Precision: 0.6686, Recall: 0.6707, F1: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████| 782/782 [00:14<00:00, 54.44it/s, loss=0.871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss: 0.8710, Acc: 0.6915, Precision: 0.6894, Recall: 0.6915, F1: 0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████| 782/782 [00:13<00:00, 56.87it/s, loss=0.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss: 0.8204, Acc: 0.7090, Precision: 0.7075, Recall: 0.7090, F1: 0.7080\n",
      "Test Accuracy: 0.5195, Precision: 0.5245, Recall: 0.5195, F1: 0.5202\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the Mish activation function\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(torch.nn.functional.softplus(x))\n",
    "\n",
    "# Poisson-based weight initialization function\n",
    "def poisson_weight_initializer(shape, lam=3.0, scale=0.01):\n",
    "    \"\"\"\n",
    "    Poisson-based weight initialization.\n",
    "    Args:\n",
    "        shape (tuple): Shape of the weight tensor.\n",
    "        lam (float): Mean of the Poisson distribution.\n",
    "        scale (float): Scaling factor to control weight magnitude.\n",
    "    Returns:\n",
    "        A PyTorch tensor with Poisson-initialized values.\n",
    "    \"\"\"\n",
    "    weights = np.random.poisson(lam, shape).astype(np.float32)\n",
    "    weights = weights - np.mean(weights)  # Zero centering\n",
    "    weights = weights / np.std(weights)   # Normalize variance\n",
    "    return torch.tensor(weights * scale, dtype=torch.float32)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the neural network model with Mish activation and Poisson-initialized weights\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 256)\n",
    "        self.mish1 = Mish()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.mish2 = Mish()\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Apply Poisson weight initialization\n",
    "        with torch.no_grad():\n",
    "            self.fc1.weight = nn.Parameter(poisson_weight_initializer(self.fc1.weight.shape, lam=5, scale=0.05))\n",
    "            self.fc2.weight = nn.Parameter(poisson_weight_initializer(self.fc2.weight.shape, lam=5, scale=0.05))\n",
    "            self.fc3.weight = nn.Parameter(poisson_weight_initializer(self.fc3.weight.shape, lam=5, scale=0.05))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.mish1(self.fc1(x))\n",
    "        x = self.mish2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix(loss=running_loss / len(trainloader))\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Epoch {epoch+1}: Loss: {running_loss / len(trainloader):.4f}, Acc: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "test_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7379590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
